{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nimika19/Mathematics/blob/main/practice_for_assessment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the matrices\n",
        "matrix_A = [[5, 32, 6], [23, 6, 87], [33, 64, 1]]\n",
        "matrix_B = [3, 5, 7]\n",
        "\n",
        "# Convert matrix_B to a matrix\n",
        "matrix_B = [[element] for element in matrix_B]\n",
        "\n",
        "# Define the function for matrix multiplication\n",
        "def matrix_multiple(m, n):\n",
        "    if len(m[0]) != len(n):\n",
        "        print(\"Error: Number of columns in the first matrix must be equal to the number of rows in the second matrix.\")\n",
        "        return None\n",
        "    result = [[0 for i in range(len(n[0]))] for i in range(len(m))]\n",
        "    for j in range(len(m)):\n",
        "        for k in range(len(n[0])):\n",
        "            for l in range(len(n)):\n",
        "                result[j][k] += m[j][l] * n[l][k]\n",
        "    return result\n",
        "\n",
        "# Perform matrix multiplication\n",
        "result_matrix = matrix_multiple(matrix_A, matrix_B)\n",
        "\n",
        "# Print the result\n",
        "for row in result_matrix:\n",
        "    print(row)\n",
        "print(result_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ST9Rz25-X8b2",
        "outputId": "bed4ce9d-92d1-4ca5-9bc6-f4ae8a3e031a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[217]\n",
            "[708]\n",
            "[426]\n",
            "[[217], [708], [426]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Practice for Newton's method, use Newton's method to find an approximate solution for f(x)\n",
        "def newton(f, f_prime, initial_guess, tolerance=1e-10, max_iteration=100):\n",
        "    \"\"\"\n",
        "    Newton's method to find an approximate solution for f(x)\n",
        "\n",
        "    Parameters:\n",
        "    f (function): the equation\n",
        "    f_prime (function): the derivative of f\n",
        "    initial_guess (float): the initial guess number\n",
        "    tolerance (float, optional): the threshold for the output. Defaults to 1e-10.\n",
        "    max_iteration (int, optional): the maximum number of iterations. Defaults to 100.\n",
        "\n",
        "    Returns:\n",
        "    float: the approximate solution\n",
        "    \"\"\"\n",
        "    x = initial_guess\n",
        "    for i in range(max_iteration):\n",
        "        # Calculate the value of f(x)\n",
        "        fx = f(x)\n",
        "        if abs(fx) < tolerance:\n",
        "            # If the absolute value of f(x) is less than the tolerance, return x\n",
        "            return x\n",
        "        # Calculate the derivative of f(x)\n",
        "        fpx = f_prime(x)\n",
        "        if fpx == 0:\n",
        "            # If the derivative is zero, return None\n",
        "            return None\n",
        "        # Update x using Newton's method\n",
        "        x = x - fx/fpx\n",
        "    # If max iterations reached without convergence, return None\n",
        "    return None\n",
        "\n",
        "# Define the function f(x)\n",
        "def f(x):\n",
        "    return x**2 + 2*x + 5\n",
        "\n",
        "# Define the derivative of f(x)\n",
        "def f_prime(x):\n",
        "    return 2*x + 2\n",
        "\n",
        "# Set the initial guess\n",
        "initial_guess = -1\n",
        "\n",
        "# Call the function newton with the input functions f and f_prime, and the initial guess\n",
        "approx_result = newton(f, f_prime, initial_guess)\n",
        "\n",
        "# Print the result\n",
        "if approx_result is not None:\n",
        "    print(\"Approximate result is:\", approx_result)\n",
        "else:\n",
        "    print(\"Newton's method did not converge\")\n"
      ],
      "metadata": {
        "id": "0EVBrPcicIiw",
        "outputId": "3a655105-3a68-4612-c8e4-02f0f29f03ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Newton's method did not converge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Practice on Least Square function\n",
        "# Least Square Function\n",
        "import numpy as np\n",
        "# Set a function Ax=b where A is a matrix and b is a vector.\n",
        "A = np.array([[1,2],[3,4],[5,6]]) #3*2 matrix\n",
        "b = np.array([7,8,9]) #3*1 vector\n",
        "#Apply with lstsq\n",
        "x, resids, rank, s = np.linalg.lstsq(A, b, rcond=None)\n",
        "print(\"Solution x:\", x)\n",
        "print(\"Residuals:\", resids)\n",
        "print(\"Rank of A:\", rank)\n",
        "print(\"Singular value of A:\", s)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIz8_fn4sRlA",
        "outputId": "231797c1-8389-4490-8d96-37957236d7dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Solution x: [-6.   6.5]\n",
            "Residuals: [7.09974815e-30]\n",
            "Rank of A: 2\n",
            "Singular value of A: [9.52551809 0.51430058]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def newton(f, s, initial_guess, tolerance=1e-5, max_iteration=1000, damping_factor=0.1, regularization=1e-8):\n",
        "    x_k = np.array(initial_guess, dtype=float)\n",
        "    for i in range(max_iteration):\n",
        "        fx = np.array(f(x_k[0], x_k[1]))\n",
        "        # Check convergence\n",
        "        if np.linalg.norm(fx) < tolerance:\n",
        "            return x_k\n",
        "        # Calculate Jacobian\n",
        "        Jac = np.array([[np.gradient(f(x_k[0], x))[0] for x in [x_k[0], x_k[0]+1e-6]],\n",
        "                         [np.gradient(f(x_k[0], x))[1] for x in [x_k[0], x_k[0]+1e-6]]])\n",
        "        Jac += np.eye(len(Jac)) * regularization  # Add regularization term\n",
        "        try:\n",
        "            spx = np.linalg.solve(Jac, -fx)\n",
        "        except np.linalg.LinAlgError:\n",
        "            print(f\"Jacobian is singular at iteration {i}. Aborting.\")\n",
        "            return None\n",
        "        # Apply damping factor\n",
        "        x_k += damping_factor * spx\n",
        "    print(\"Maximum iterations reached without convergence.\")\n",
        "    return None\n",
        "\n",
        "def f(x1, x2):\n",
        "    fx1 = x1 + 2*x2 - 2\n",
        "    fx2 = x1**2 + 4*x2**2 - 4\n",
        "    return np.array([fx1, fx2])\n",
        "\n",
        "def s(x1, x2):\n",
        "    coefficients = np.array([[1, 2], [2*x1, 8*x2]])\n",
        "    constants = np.array([-f(x1, x2)[0], -f(x1, x2)[1]])\n",
        "    return np.linalg.solve(coefficients, constants)\n",
        "\n",
        "initial_guess = [1, 2]\n",
        "approx_result = newton(f, s, initial_guess)\n",
        "if approx_result is not None:\n",
        "    print(\"Approximate result is:\", approx_result)\n",
        "else:\n",
        "    print(\"Newton's method did not converge\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiTY1yYjuMbF",
        "outputId": "8f28b22a-30f0-4bf1-c668-4e302ffad668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacobian is singular at iteration 1. Aborting.\n",
            "Newton's method did not converge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def broyden(f, initial_guess, tolerance=1e-5, max_iteration=1000):\n",
        "    x_k = np.array(initial_guess, dtype=float)\n",
        "    b_k = np.array([[np.gradient(f(x_k[0], x))[0] for x in [x_k[0], x_k[0]+1e-6]],\n",
        "                     [np.gradient(f(x_k[0], x))[1] for x in [x_k[0], x_k[0]+1e-6]]])\n",
        "    for i in range(max_iteration):\n",
        "        fx = np.array(f(x_k[0], x_k[1]))\n",
        "        # Check convergence\n",
        "        if np.linalg.norm(fx) < tolerance:\n",
        "            return x_k\n",
        "        # Check if Jacobian matrix is singular\n",
        "        if np.linalg.det(b_k) == 0:\n",
        "            print(\"Jacobian matrix is singular. Aborting.\")\n",
        "            return None\n",
        "        # Solve b_k*delta_x = -f(x_k)\n",
        "        try:\n",
        "            delta_x = np.linalg.solve(b_k, -fx)\n",
        "        except np.linalg.LinAlgError:\n",
        "            print(\"Jacobian matrix is singular. Aborting.\")\n",
        "            return None\n",
        "        x_k2 = x_k + delta_x\n",
        "        fx2 = np.array(f(x_k2[0], x_k2[1]))\n",
        "        y_k = fx2 - fx\n",
        "        s_k = x_k2 - x_k\n",
        "        b_k = b_k + np.outer((y_k - np.dot(b_k, s_k)), s_k) / np.dot(s_k,s_k)\n",
        "        x_k = x_k2\n",
        "    print(\"Maximum iterations reached without convergence.\")\n",
        "    return None\n",
        "\n",
        "def f(x1, x2):\n",
        "    fx1 = x1 + 2*x2 - 2\n",
        "    fx2 = x1**2 + 4*x2**2 - 4\n",
        "    return np.array([fx1, fx2])\n",
        "\n",
        "initial_guess = [1,2]\n",
        "approx_result = broyden(f, initial_guess)\n",
        "if approx_result is not None:\n",
        "    print(\"Approximate result is:\", approx_result)\n",
        "else:\n",
        "    print(\"Broyden's method did not converge\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnXZMf9kug0G",
        "outputId": "005a6c8a-51fd-4052-8f89-9c4f3df4481e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jacobian matrix is singular. Aborting.\n",
            "Broyden's method did not converge\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the time and speed data\n",
        "time = np.array([0, 10, 20, 30, 40])\n",
        "speed = np.array([0, 15, 30, 45, 60])\n",
        "\n",
        "# Define the timestamps for which we want to estimate the speed\n",
        "timestamps = np.array([5, 25, 35])\n",
        "\n",
        "# Perform linear interpolation\n",
        "speed_interp = np.interp(timestamps, time, speed)\n",
        "\n",
        "print(\"Estimated speed at 5 seconds:\", speed_interp[0])\n",
        "print(\"Estimated speed at 25 seconds:\", speed_interp[1])\n",
        "print(\"Estimated speed at 35 seconds:\", speed_interp[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egD-qbMHu4_n",
        "outputId": "d5c1decf-4a5e-401d-d53b-f30cc49f7033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated speed at 5 seconds: 7.5\n",
            "Estimated speed at 25 seconds: 37.5\n",
            "Estimated speed at 35 seconds: 52.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Define the profit function\n",
        "def profit_function(x):\n",
        "    x1, x2 >= 0\n",
        "    return -((x1-4)**2 + (x2-6)**2 - 36)\n",
        "\n",
        "# Define Initial guess\n",
        "ini_guess = [-5,5]\n",
        "\n",
        "#Define the bounds for x1 and x2\n",
        "bounds = [(-5,0), (0,5)]\n",
        "\n",
        "\n",
        "# Initialize the optimization problem\n",
        "res = minimize(profit_function, [0, 0], method=\"Nelder-Mead\", bounds=bounds)\n",
        "\n",
        "# Print the optimal values of x1 and x2\n",
        "print(\"Optimal x1:\", res.x[0])\n",
        "print(\"Optimal x2:\", res.x[1])\n",
        "\n",
        "# Print the maximum profit\n",
        "print(\"Maximum profit:\", -res.fun)"
      ],
      "metadata": {
        "id": "0Y-VYaw4_dhk",
        "outputId": "a37d03a0-3a84-4cce-f220-d969cc1bccf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'x1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-ce2c076373b1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Initialize the optimization problem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofit_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Nelder-Mead\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# Print the optimal values of x1 and x2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nelder-mead'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         res = _minimize_neldermead(fun, x0, args, callback, bounds=bounds,\n\u001b[0m\u001b[1;32m    702\u001b[0m                                    **options)\n\u001b[1;32m    703\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'powell'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_minimize_neldermead\u001b[0;34m(func, x0, args, callback, maxiter, maxfev, disp, return_all, initial_simplex, xatol, fatol, adaptive, bounds, **unknown_options)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m             \u001b[0mfsim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_MaxFuncCallError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36mfunction_wrapper\u001b[0;34m(x, *wrapper_args)\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0mncalls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;31m# A copy of x is sent to the user function (gh13740)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0;31m# Ideally, we'd like to a have a true scalar returned from f(x). For\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;31m# backwards-compatibility, also allow np.array([1.3]),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-ce2c076373b1>\u001b[0m in \u001b[0;36mprofit_function\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Define the profit function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprofit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x1' is not defined"
          ]
        }
      ]
    }
  ]
}